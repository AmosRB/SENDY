const express = require('express');
const cors = require('cors');
const scrapeProductFromAnySite = require('./scrapers/productScraper'); // âœ… ×¢×“×›×•×Ÿ ×›××Ÿ
const fs = require('fs');
const path = require('path');
const urlLib = require('url');

const app = express();
app.use(cors());

// ×˜×¢×™× ×ª API ×©×œ × ×™×”×•×œ ×¡×œ×§×˜×•×¨×™×
const selectorsRoute = require('./routes/selectors');
app.use('/api/selectors', express.json(), selectorsRoute);

// ×ž×™×§×•× ×”×§×•×‘×¥ ×”×ž×§×•×ž×™ ×©×œ ×”×¡×œ×§×˜×•×¨×™×
const SELECTOR_CACHE_PATH = path.join(__dirname, './data/selectors-cache.json');

// ×—×™×œ×•×¥ ×“×•×ž×™×™×Ÿ ×ž×ª×•×š ×§×™×©×•×¨
function extractDomain(url) {
  const parsed = urlLib.parse(url);
  return parsed.hostname.replace('www.', '');
}

// ×‘×“×™×§×” ×× ×”×“×•×ž×™×™×Ÿ ×›×‘×¨ × ×œ×ž×“ ×‘×¢×‘×¨
function checkSelectorOrigin(domain) {
  if (!fs.existsSync(SELECTOR_CACHE_PATH)) return 'new';
  const cache = JSON.parse(fs.readFileSync(SELECTOR_CACHE_PATH));
  return cache[domain] ? 'cache' : 'new';
}

// × ×ª×™×‘ ×—×™×¦×•× ×™: ×—×™×œ×•×¥ × ×ª×•× ×™ ×ž×•×¦×¨
app.get('/extract', async (req, res) => {
  const { url } = req.query;
  if (!url) return res.status(400).json({ error: 'Missing URL' });

  const domain = extractDomain(url);
  const source = checkSelectorOrigin(domain);
  console.log(`ðŸŸ¡ Processing URL: ${url}`);
  console.log(`ðŸ” Domain: ${domain} â†’ Selector source: ${source === 'cache' ? 'ðŸ—‚ cache' : 'ðŸ§  new learning'}`);

  try {
    const data = await scrapeProductFromAnySite(url); // âœ… ×©×™×ž×•×© ×‘×¤×•× ×§×¦×™×” ×”×—×“×©×”
    if (!data) return res.status(500).json({ error: 'Failed to extract data' });

    console.log(`âœ… Extraction success for ${domain}`);
    res.json(data);
  } catch (err) {
    console.error('âŒ Error in /extract:', err.message);
    res.status(500).json({ error: 'Scraping failed' });
  }
});

// ×”×¤×¢×œ×ª ×”×©×¨×ª
const PORT = 4135;
app.listen(PORT, () => {
  console.log(`ðŸŸ¢ API server running on http://localhost:${PORT}`);
});
